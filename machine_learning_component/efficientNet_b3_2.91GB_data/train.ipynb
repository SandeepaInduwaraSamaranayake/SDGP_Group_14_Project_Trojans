{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# INSTALL numpy. COMMENT THIS IF numpy IS ALREADY INSTALLED.\n",
    "# %pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# INSTALL tensorflow. COMMENT THIS IF tensorflow IS ALREADY INSTALLED.\n",
    "# %pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# INSTALL tensorflow_hub. COMMENT THIS IF tensorflow_hub IS ALREADY INSTALLED.\n",
    "# %pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# INSTALL tqdm. COMMENT THIS IF tqdm IS ALREADY INSTALLED.\n",
    "# %pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# INSTALL torchvision. COMMENT THIS IF torchvision IS ALREADY INSTALLED.\n",
    "# %pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# INSTALL ipynb. COMMENT THIS IF ipynb IS ALREADY INSTALLED\n",
    "# %pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# INSTALL ipynb. COMMENT THIS IF ipynb IS ALREADY INSTALLED\n",
    "# %pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# IF YOU WANT TO CHECK ALL PACKAGES ARE INSTALLED SUCCESSFULLY.\n",
    "# UNCOMMENT THE FOLLOWING LINE AND CHECK FOR INSTALLED PACKAGES.\n",
    "# %pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# INSTALL matplotlib. COMMENT THIS IF ipynb IS ALREADY INSTALLED\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"                                     # IGNORE THE WARNINGS FROM IMPORTING TENSERFLOW.\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_hub as hub                                                 # USING TENSORFLOW_HUB WE WILL HAVE A PRETRAINED EFFICIENT MODEL THAT WE WILL BE USING.\n",
    "from tqdm import tqdm                                                        # JUST FOR GETTING A PROGRESS BAR FOR THE CURRENT EPOCH.                                                \n",
    "from ipynb.fs.full.dataset import get_loaders                                # we need to import dataset.ipynb notebook.\n",
    "import matplotlib.pyplot as plt                                              # IMPORT matplotlib to create graphs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting variables and environment (using EfficientNetB3 with 20 Epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices( \"GPU\" )                  # SETTING THE PHYSICAL DEVICES.\n",
    "if len( physical_devices ) > 0:                                              # MIGHT NOT NECESSARY, BUT ITS SAFE PRECAUSION TO TAKE.\n",
    "    tf.config.experimental.set_memory_growth( physical_devices[0], True)\n",
    "\n",
    "URL = \"https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1\"        # URL TO TENSORFLOW HUB WHERE DOWNLOAD THE FEATURE VECTOR ASSOCIATE TO AN EFFICIENTNET MODEL.\n",
    "                                                                             # HERE WE ARE GOING TO USE THE SMALLEST EFFICIENTNET MODEL JUST TO MAKE IT BIT FASTER TO TRAIN.\n",
    "                                                                             # THAT IS EFFICIENTNET B0 MODEL.\n",
    "IMG_SIZE = 300                                                               # IMAGE SIZE DEPEND ON THE MODEL. IF INCREASE b0 TO b1, YOU NEED TO CHANGE THE IMAGE SIZE TO 240.\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 355\n",
    "NUM_EPOCHS = 10\n",
    "DATA_DIR = \"data/\"\n",
    "MODEL_PATH = \"efficientnetb0/\"                                               # SETTING WHERE WE WANT TO SAVE THE MODEL.\n",
    "LOAD_MODEL = False\n",
    "\n",
    "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"1\"\n",
    "os.environ[\"TFHUB_CACHE_DIR\"] = \"E:/SDGP_TROJANS/machine_learning_component/efficientNet_b3_2.91GB_data/TFHUB_CACHE\"    # WHERE TO SAVE THE CACHE FILES WHILE BUILDING MODEL."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting sequential model and building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def get_model( url, img_size, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        hub.KerasLayer( url, trainable = True ),\n",
    "        layers.Dense( 1000, activation = \"relu\" ),\n",
    "        layers.Dropout( 0.3 ),\n",
    "        layers.Dense( num_classes, activation = \"softmax\" ),\n",
    "    ])\n",
    "\n",
    "    model.build( [None, img_size, img_size, 3] )                              # BUILDING THE MODEL. None FOR THE BATCH. 3 IS NUMBER OF CHANNELS.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function                                                                  # WRAPPING WITH tf.function FOR SOME ADDITIONAL OPTIMIZATION.\n",
    "def train_step( data, labels, acc_metric, model, loss_fn, optimizer ):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model( data, training = True )\n",
    "        loss = loss_fn( labels, predictions )\n",
    "\n",
    "    gradients = tape.gradient( loss, model.trainable_weights )\n",
    "    optimizer.apply_gradients( zip( gradients, model.trainable_weights ) )\n",
    "    acc_metric.update_state( labels, predictions )                             # AT LAST UPDATING THE ACCURACY METRIC, WHICH WILL BE SORT OF RUNNING ACCURACY ACROSS THE EPOCHS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model( ds_validation, model ):\n",
    "    accuracy_metric =  keras.metrics.SparseCategoricalAccuracy()               # HAVING accuracy_metric TO KEEP TRACK OF WHAT IS THE ACCURACY ACROSS THE VALIDATION SET.\n",
    "\n",
    "    for idx, ( data, labels) in enumerate( ds_validation ):\n",
    "        # CONVET THE DATA TO HAVE THE CORRECT DIMENSIONS.\n",
    "        data = data.permute( 0, 2, 3, 1 )                \n",
    "        data = tf.convert_to_tensor( np.array( data ) )\n",
    "        labels = tf.convert_to_tensor( np.array( labels ) )\n",
    "\n",
    "        y_pred = model( data, training = False )\n",
    "        accuracy_metric.update_state( labels, y_pred )\n",
    "\n",
    "    accuracy = accuracy_metric.result()\n",
    "    print( f\"Accuracy over validation set: { accuracy }\" )\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting (training and validation loss) and ( training and validation accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def plotTheGraphs(train_loss, val_loss, train_acc, val_acc):\n",
    "    # Plot training and validation loss\n",
    "    plt.plot(train_loss, label='train')\n",
    "    plt.plot(val_loss, label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.plot(train_acc, label='train')\n",
    "    plt.plot(val_acc, label='val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply a learning rate scheduler\n",
    "# Training Loop\n",
    "# calculate train loss, train accuracy, validation loss, validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_loader, dev_loader = get_loaders( DATA_DIR + \"train\", DATA_DIR + \"dev\", BATCH_SIZE, IMG_SIZE )  \n",
    "    \n",
    "    # SETUP THE TRAINING.\n",
    "    if LOAD_MODEL:\n",
    "        print(\"Loading model\")\n",
    "        model = keras.models.load_model( MODEL_PATH )\n",
    "    \n",
    "    # IF WE WANT TO CONTINUE THE TRAINING, WE CAN START THE TRAINING AND RERUNNING IT. OTHERWISE, WE CAN USE THE CREATED get_model() function.\n",
    "    else:\n",
    "        print(\"Building model\")\n",
    "        model = get_model( URL, IMG_SIZE, NUM_CLASSES )\n",
    "\n",
    "    # SETUP THE OPTIMIZER\n",
    "    # SPECIFY THE LEARNING RATE(lr) AS 3e-4. \n",
    "    # WE ARE NOT ACTUALLY GOING TO PLAYing AROUND TOO MUCH HEAVY LEARNING RATE.\n",
    "    # YOU CAN USE LEARNING RATE SCHEDULAR, THAT WOULD MOST LIKELY IMPROVE THE MODEL. \n",
    "\n",
    "    # USING LEARNING RATE SCHEDULER INSTEAD OF HARDCODING LEARNING RATE AS FOLLOWING COMMENTED LINE (e.g. optimizer = keras.optimizers.Adam( learning_rate = 3e-4 )).\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay( initial_learning_rate = 1e-3, decay_steps = 10000, decay_rate = 0.9 )\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = lr_schedule)\n",
    "\n",
    "    # optimizer = keras.optimizers.Adam( learning_rate = 3e-4 )\n",
    "\n",
    "    # CREATING LOSS FUNCTION.\n",
    "    loss_fn = keras.losses.SparseCategoricalCrossentropy( from_logits = False )\n",
    "    # THIS IS FOR THE RUNNING ACCURACY.\n",
    "    acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "    train_loss = []\n",
    "    train_accuracy = []\n",
    "    val_loss = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    # TRAINING LOOP\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        epoch_train_loss = []\n",
    "        epoch_train_accuracy = []\n",
    "\n",
    "        for idx, ( data, labels ) in enumerate( tqdm(train_loader) ):\n",
    "\n",
    "            # SINCE WE ARE LOADING DATA IN PyTorch WE NEED TO SWAP THE ACCESS FOR THE NUMBER OF CHANNELS, BECAUSE THESE CHANNELS ARE NOT STRUCTURED IN THE SAMA WAY.\n",
    "            # PyTorch: N X C X H X W       TensorFlow: N X H X W X C       N -      , H - HEight  , W - WIDTH  ,  C - CHANNELS\n",
    "            # N IS IN THE SAME POSITION IN BOTH. H HAS 2 INDEX, GET H TO SECOND POSITION.LIKEWISE...\n",
    "\n",
    "            data = data.permute( 0, 2, 3, 1 )\n",
    "            data = tf.convert_to_tensor( np.array( data ) )\n",
    "            labels = tf.convert_to_tensor( np.array( labels ) )\n",
    "\n",
    "            train_step( data, labels, acc_metric, model, loss_fn, optimizer )\n",
    "\n",
    "            # CHECKING THE INDEX\n",
    "            if idx % 150 == 0 and idx > 0:\n",
    "                # GET THE TRAINING ACCRACY, PRINT THAT ACCURACY. REMEMBER, THIS IS THE RUNNING TRAINING ACCURACY SO FAR IN THE EPOCHS.\n",
    "                train_acc =  acc_metric.result()\n",
    "                print(f\"Accuracy over epoch (so far) {train_acc}\" )\n",
    "                \n",
    "                # evaluation.\n",
    "                evaluate_model( dev_loader, model )\n",
    "                model.save( MODEL_PATH )\n",
    "\n",
    "\n",
    "            # append loss and accuracy of the current epoch to relevant lists.\n",
    "            epoch_train_loss.append( loss_fn(labels, model(data)).numpy() )\n",
    "            epoch_train_accuracy.append( acc_metric.result().numpy() )\n",
    "\n",
    "        # append the mean values of both epoch_train_loss and epoch_train_accuracy to the \n",
    "        train_loss.append( np.mean(epoch_train_loss) )\n",
    "        train_accuracy.append( np.mean(epoch_train_accuracy) )\n",
    "\n",
    "\n",
    "        epoch_val_loss = []\n",
    "        epoch_val_accuracy = []\n",
    "\n",
    "        for idx, (data, labels) in enumerate(dev_loader):\n",
    "\n",
    "            # Swap the access for the number of channels to match TensorFlow\n",
    "            data = data.permute(0, 2, 3, 1)\n",
    "            data = tf.convert_to_tensor(np.array(data))\n",
    "            labels = tf.convert_to_tensor(np.array(labels))\n",
    "\n",
    "            # Predict on validation data\n",
    "            epoch_val_loss.append( loss_fn(labels, model(data)).numpy() )\n",
    "            acc_metric.update_state( labels, model(data) )\n",
    "            epoch_val_accuracy.append( acc_metric.result().numpy() )\n",
    "\n",
    "\n",
    "        val_loss.append( np.mean(epoch_val_loss) )\n",
    "        val_accuracy.append( np.mean(epoch_val_accuracy) )\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(  f\"Epoch {epoch+1}/{NUM_EPOCHS}, Train Loss: {epoch_train_loss[-1]:.4f}, Train Acc: {epoch_train_accuracy[-1]:.4f}, Val Loss: {epoch_val_loss[-1]:.4f}, Val Acc: {epoch_val_accuracy[-1]:.4f}\" )\n",
    "\n",
    "        # Reset the accuracy metric\n",
    "        acc_metric.reset_states()\n",
    "\n",
    "    # plot the graphs\n",
    "    plotTheGraphs( train_loss, val_loss, train_accuracy, val_accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
